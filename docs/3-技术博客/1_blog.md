# 从传统搜索到智能问答：葡萄城自研 RAG 系统的技术实践与工程落地

## 一、引言

在数字化转型浪潮下，企业知识服务体系正经历着深刻变革。如何让用户高效获取所需信息，成为提升产品竞争力和用户满意度的关键。葡萄城作为企业级开发工具与解决方案提供商，长期致力于知识服务体系的建设。本文将系统介绍葡萄城自研 RAG（Retrieval-Augmented Generation，检索增强生成）智能问答系统的技术创新、架构设计与工程实践，分享我们在智能搜索与问答领域的探索与思考。

---

## 二、项目缘起：从搜索到智能问答的需求升级

### 1. 现状与挑战

葡萄城已建立了完善的知识服务体系，包括标准化文档、技术社区、搜索平台等。现有“葡萄城搜索中心”支持跨平台内容检索，覆盖官网、博客、社区、视频等多种内容源。然而，随着知识库规模的扩大和用户需求的提升，传统基于关键词的搜索方式暴露出诸多不足：

-   用户难以精准定位帮助文档中的功能说明；
-   技术支持人员难以快速查重和定位历史解决方案；
-   方案搜寻效率低，用户体验不佳。

### 2. 技术探索与自研动因

随着大语言模型（LLM）技术的快速发展，基于 RAG 的智能问答成为提升知识服务能力的理想路径。我们调研了多种开源与商业化 RAG 方案，发现它们难以直接适配葡萄城多源异构的数据结构和业务需求。为此，我们决定自研 RAG 系统，目标包括：

-   适配多样化内容结构（如帮助文档、论坛帖子等）；
-   支持高频动态更新，保障知识库时效性；
-   灵活扩展，满足未来产品演进需求；
-   性能与维护可控，便于长期运维。

---

## 三、创新点：QA 预生成与“问题对问题”匹配

### 1. 传统 RAG 的局限

传统 RAG 方案通常将用户问题与文档段落直接匹配，但用户提问多为简洁疑问句，文档内容则为陈述性描述，二者在语义表达上存在结构性差异，导致检索准确率受限。

### 2. 预生成 QA 对的创新

我们基于大语言模型的信息抽取能力，提出了“问题与问题匹配”的创新思路：

-   利用 LLM 为每段文档生成“预设问题”，将原始文档转化为多个 QA 对（问题+答案）；
-   用户问题与预设问题进行语义一致的精准匹配，显著提升检索效果；
-   每个 QA 对还配有详细答案（Full Answer）和上下文摘要（Summary），为后续生成环节提供丰富上下文。

这种方式不仅解决了语义错位问题，还能将一篇文档拆解为多个知识点，极大提升了知识库的颗粒度和检索相关性。

---

## 四、产品设计：融合搜索与智能问答的极致体验

### 1. 界面设计

我们摒弃了传统对话式 AI 助手的设计，转而采用“传统搜索界面 + 智能问答”的混合方案：

-   **首页（Home）**：聚焦搜索，支持产品切换，输入框简洁直观；
-   **搜索页（Search）**：顶部导航+产品切换器+搜索框，智能回答区域采用打字机效果逐字输出，搜索结果分为“全部/帮助文档/求助中心/专题教程”四个选项卡，支持数量提示与禁用。

### 2. 智能回答与多轮对话

-   智能回答区域支持加载动画、逐字生成、停止生成、复制、追问等操作；
-   支持多轮追问，自动折叠历史内容，保持上下文连贯；
-   回答区提供“有用/没用”反馈，便于后续优化。

### 3. 搜索结果优化

-   选项卡显示结果数量，无结果时自动禁用；
-   帮助文档类结果支持“展开更多”查看详细答案，无需跳转原文；
-   搜索结果无分页，提升信息获取效率。

---

## 五、技术架构：三阶段 RAG 流程与多通道混合检索

### 1. 架构总览

系统采用典型的三阶段 RAG 架构：

-   **构建（ETL）**：文档采集、QA 对生成、向量化、入库；
-   **检索（Retrieval）**：多通道混合检索（稀疏+稠密），RRF 融合排序；
-   **生成（Generation）**：基于 LLM 和检索结果生成自然语言回答。

### 2. 知识构建（ETL）

-   支持多源内容采集（帮助文档、论坛、API 文档等）；
-   基于 LLM 生成结构化 QA 对，人工抽检保证质量；
-   向量化采用稀疏（BM25）+稠密（Dense Vector）双通道，支持前缀机制区分不同文档场景；
-   每条知识条目包含问题、答案、详细答案、摘要、链接、标题、分类、时间等丰富元数据。

### 3. 检索机制

-   混合检索策略：BM25（关键词）+ Dense（语义）双通道，分别检索问题和答案字段；
-   RRF（Reciprocal Rank Fusion）融合排序，提升相关性与多样性；
-   TopK 策略，最终返回最优结果集。

### 4. 生成机制

-   LLM 结合用户问题与检索结果生成自然语言回答，附带文档链接；
-   支持“思考模式”，输出中间推理过程，增强信任感；
-   多轮对话场景下，自动识别用户意图并改写问题，保证上下文连贯。

---

## 六、工程落地：高可用、可扩展的系统实践

### 1. 部署架构

系统分为两大模块：

-   **知识检索与问答服务**：Qdrant 向量数据库、MySQL 日志与反馈、Server 应用（API）、Client 应用（前端）、第三方 LLM 服务接入；
-   **知识库构建服务（ETL）**：定时任务驱动的文档采集、QA 生成、向量化与入库，支持全量与增量更新。

### 2. 请求限流与熔断

-   采用移动窗口算法实现多维度限流（接口/时间），防止突发流量冲击；
-   支持熔断与降级机制，保障系统稳定性。

### 3. 性能与监控

-   检索性能：2 秒内返回结果，支持异步加载；
-   生成性能：依赖 LLM，平均 30 秒内完成；
-   全链路监控：请求成功率、响应时间、LLM 调用、向量库查询等多维度指标。

### 4. 用户体验优化

-   前端界面简洁直观，支持 Markdown 展示详细答案；
-   多轮对话与上下文记忆，提升连续交互体验；
-   用户反馈机制完善，所有反馈入库用于后续优化。

---

## 七、落地效果与未来展望

### 1. 实际应用成效

-   首批覆盖活字格、Wyn、SpreadJS、GcExcel 四大核心产品，支持帮助文档与技术社区内容；
-   日活用户数、提问频次、热门问题分布等数据持续增长；
-   答案准确率与用户满意度显著提升，系统稳定性良好。

### 2. 持续优化方向

-   拓展更多内容源（API 文档、视频、插件等）；
-   优化检索与生成策略，提升响应速度与准确率；
-   深化用户反馈分析，驱动系统持续迭代；
-   探索模型微调与新功能（如图像复制、链接分享等）。

---

## 八、结语

葡萄城自研 RAG 智能问答系统，融合了前沿的自然语言处理技术与工程化最佳实践，实现了从传统搜索到智能问答的跨越。我们相信，随着技术的不断演进和用户需求的持续升级，智能知识服务将在企业数字化转型中发挥越来越重要的作用。欢迎业界开发者交流探讨，共同推动智能问答技术的创新与落地！

---

如需了解更多细节，欢迎访问葡萄城官网或关注我们的技术社区。
